{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for analysis\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import csv\n",
    "\n",
    "# Libraries for visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale = 1.2)\n",
    "\n",
    "# Allows charts to appear in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DomOriMag(u_crop, v_crop, ori_res):\n",
    "    \n",
    "    mag, ang = cv.cartToPolar(u_crop, v_crop, angleInDegrees = True)\n",
    "    \n",
    "    ang = np.floor(ang/ori_res) # Quantizing the angles to 360/res bins\n",
    "    ang = np.reshape(ang, (1, -1))\n",
    "    \n",
    "    mag = np.around(mag) # Because we don't need float percision for magnitude, we round them here\n",
    "    mag = np.reshape(mag, (1, -1))\n",
    "    \n",
    "    oriBins = np.uint8(360/ori_res)\n",
    "    OriMagHist = np.zeros(oriBins)\n",
    "    for i in range(oriBins):\n",
    "        indexes = np.where(ang == i)\n",
    "        OriMagHist[i] = np.sum(mag[indexes])\n",
    "        \n",
    "    domOriTemp = np.argmax(OriMagHist)\n",
    "    domOriMagsIdx = np.where(ang == domOriTemp)\n",
    "    domOriMags = mag[domOriMagsIdx]\n",
    "    \n",
    "    maxMag = np.max(domOriMags)\n",
    "    magHist, bins = np.histogram(domOriMags, bins = np.arange(maxMag + 2))\n",
    "    \n",
    "    return domOriTemp * ori_res, magHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def childFlow(frame1_gray, frame2_gray, bbox, direction):\n",
    "    \n",
    "    # In following lines, we will do two sets of things. First, due to our previous angle,\n",
    "    # we will choose whether extend our checking bbox in the right side or left side. Second,\n",
    "    # we check if our bbox is going outside or not and then, correcting its bounderies\n",
    "    \n",
    "    bbox_new = np.copy(bbox)\n",
    "    # Check right side movement of bbox\n",
    "    if direction == \"right\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1], bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    elif direction == \"left\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1]-bbox_w, bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    \n",
    "    # Now, we will calculate optical flow and take our crop from previous step\n",
    "    \n",
    "    subtFrames = cv.absdiff(frame2_gray, frame1_gray)\n",
    "    ret, thresh = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    flow = cv.calcOpticalFlowFarneback(frame1_gray, frame2_gray, None, 0.5, 5, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    flow_u = flow[...,0] * thresh/255\n",
    "    flow_v = flow[...,1] * thresh/255\n",
    "            \n",
    "    u_crop = flow_u[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    v_crop = flow_v[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    \n",
    "    return u_crop, v_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def childFlow_1(frame1_gray, frame2_gray, bbox, direction):\n",
    "    \n",
    "    # In following lines, we will do two sets of things. First, due to our previous angle,\n",
    "    # we will choose whether extend our checking bbox in the right side or left side. Second,\n",
    "    # we check if our bbox is going outside or not and then, correcting its bounderies\n",
    "    \n",
    "    bbox_new = np.copy(bbox)\n",
    "    # Check right side movement of bbox\n",
    "    if direction == \"right\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1], bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    elif direction == \"left\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1]-bbox_w, bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    \n",
    "    # Now, we will calculate optical flow and take our crop from previous step\n",
    "    fr1_gray_crop = frame1_gray[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    fr2_gray_crop = frame2_gray[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    \n",
    "    subtFrames = cv.absdiff(fr2_gray_crop, fr1_gray_crop)\n",
    "    ret, thresh = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    flow = cv.calcOpticalFlowFarneback(fr1_gray_crop, fr2_gray_crop, None, 0.5, 5, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    u_crop = flow[...,0] * thresh/255\n",
    "    v_crop = flow[...,1] * thresh/255\n",
    "    \n",
    "    return u_crop, v_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def childFlow_2(frame1_gray, frame2_gray, bbox, direction):\n",
    "    \n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 4,\n",
    "                      criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 1, 0.03))\n",
    "    \n",
    "    bbox_new = np.copy(bbox)\n",
    "    \n",
    "    # Check right side movement of bbox\n",
    "    if direction == \"right\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1], bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    elif direction == \"left\":\n",
    "        bbox_new = np.array([bbox[0], bbox[1]-bbox_w, bbox_l, 2*bbox_w])\n",
    "        bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "        \n",
    "    # Now, we will calculate optical flow and take our crop from previous step\n",
    "    \n",
    "    subtFrames = cv.absdiff(frame2_gray, frame1_gray)\n",
    "    ret, thresh = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    flow_u = np.zeros((np.size(frame1_gray, 0), np.size(frame1_gray, 1)))\n",
    "    flow_v = np.zeros((np.size(frame1_gray, 0), np.size(frame1_gray, 1)))\n",
    "    \n",
    "    ptsRow, ptsCol = np.nonzero(thresh)\n",
    "    pts0 = np.transpose(np.array([ptsRow, ptsCol], dtype=np.float32))\n",
    "    \n",
    "    pts1, st, err = cv.calcOpticalFlowPyrLK(frame1_gray, frame2_gray, pts0, None, **lk_params)\n",
    "    e, f = np.nonzero(st)\n",
    "    good_pts0 = pts0[e]\n",
    "    good_pts1 = pts1[e]\n",
    "    \n",
    "    u_v = (good_pts1 - good_pts0)\n",
    "    flow_u[np.int16(good_pts0[:, 0]), np.int16(good_pts0[:, 1])] = u_v[:, 0]\n",
    "    flow_v[np.int16(good_pts0[:, 0]), np.int16(good_pts0[:, 1])] = u_v[:, 1]\n",
    "    \n",
    "    u_crop = flow_u[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    v_crop = flow_v[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    \n",
    "    return u_crop, v_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oriJumpReduct(val, prv_val, cntr):\n",
    "    if np.abs(val - prv_val) > 90 and np.abs(val - prv_val) < 270:\n",
    "        if cntr == 0:\n",
    "            val = prv_val\n",
    "            cntr += 1\n",
    "        else:\n",
    "            cntr = 0\n",
    "    else:\n",
    "        cntr = 0\n",
    "    \n",
    "    return val, cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MagOriToMove(domMag, domOri):\n",
    "    \n",
    "    rowMove = domMag * np.sin(np.deg2rad(domOri))\n",
    "    colMove = domMag * np.cos(np.deg2rad(domOri))\n",
    "    rowMove = np.int32(rowMove)\n",
    "    colMove = np.int32(colMove)\n",
    "    \n",
    "    return rowMove, colMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MoveComp(frame1_gray, frame2_gray, domMag):\n",
    "    \n",
    "    subtFrames = cv.subtract(frame1_gray, frame2_gray)\n",
    "    ret, threshold = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    w, x, y, z = bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]\n",
    "    w, x, y, z = np.clip(np.array([w, x, y, z]), [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    \n",
    "    up, left, down, right = 0, 0, 0, 0\n",
    "    if bbox[0] > 0:\n",
    "        up = threshold[w, x:z]\n",
    "    if bbox[1] > 0:\n",
    "        left = threshold[w:y, x]\n",
    "    if bbox[0] + bbox[2] < 1080:\n",
    "        down = threshold[y, x:z]\n",
    "    if bbox[1] + bbox[3] < 1920:\n",
    "        right = threshold[w:y, z]\n",
    "    \n",
    "    if domMag < 40:\n",
    "        domMag = 40\n",
    "    \n",
    "    rowComp, colComp = 0, 0\n",
    "    \n",
    "    if np.count_nonzero(up) > 0:\n",
    "        rowComp -= domMag * 0.75\n",
    "    if np.count_nonzero(left) > 0:\n",
    "        colComp -= domMag * 0.75\n",
    "    if np.count_nonzero(down) > 0:\n",
    "        rowComp += domMag * 0.75\n",
    "    if np.count_nonzero(right) > 0:\n",
    "        colComp += domMag * 0.75\n",
    "    \n",
    "    rowComp = np.int32(rowComp)\n",
    "    colComp = np.int32(colComp)\n",
    "    \n",
    "    return rowComp, colComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MoveComp_1(frame1_gray, frame2_gray, domMag):\n",
    "    \n",
    "    subtFrames = cv.subtract(frame1_gray, frame2_gray)\n",
    "    ret, threshold = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    w, x, y, z = bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]\n",
    "    w, x, y, z = np.clip(np.array([w, x, y, z]), [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "    \n",
    "    up, left, down, right = 0, 0, 0, 0\n",
    "    if bbox[0] > 0:\n",
    "        up = threshold[w, x:z]\n",
    "    if bbox[1] > 0:\n",
    "        left = threshold[w:y, x]\n",
    "    if bbox[0] + bbox[2] < 1080:\n",
    "        down = threshold[y, x:z]\n",
    "    if bbox[1] + bbox[3] < 1920:\n",
    "        right = threshold[w:y, z]\n",
    "    \n",
    "    if domMag < 40:\n",
    "        domMag = 40\n",
    "    \n",
    "    rowComp, colComp = 0, 0\n",
    "    \n",
    "    if np.count_nonzero(up) > 0:\n",
    "        rowComp -= domMag * 0.75\n",
    "    if np.count_nonzero(left) > 0:\n",
    "        colComp -= domMag * 1\n",
    "    if np.count_nonzero(down) > 0:\n",
    "        rowComp += domMag * 0.75\n",
    "    if np.count_nonzero(right) > 0:\n",
    "        colComp += domMag * 1\n",
    "        \n",
    "    if np.count_nonzero(right) > 0 and np.count_nonzero(left) > 0:\n",
    "        if np.count_nonzero(right) > np.count_nonzero(left):\n",
    "            colComp += domMag * 1\n",
    "        elif np.count_nonzero(right) < np.count_nonzero(left):\n",
    "            colComp -= domMag * 1\n",
    "    \n",
    "    if bbox[0] > frame_l - bbox_l:\n",
    "        if np.count_nonzero(threshold[w+10, x:z]) < 10:\n",
    "            rowComp += 5\n",
    "    if bbox[1] < 0:\n",
    "        if np.count_nonzero(threshold[w:y, z-10]) < 10:\n",
    "            colComp -= 5\n",
    "    \n",
    "    rowComp = np.int32(rowComp)\n",
    "    colComp = np.int32(colComp)\n",
    "    \n",
    "    return rowComp, colComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss_vectorized(W, X, y, reg):\n",
    "  \n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    num_train = X.shape[0]\n",
    "\n",
    "    scores = X.dot(W)\n",
    "    yi_scores = scores[np.arange(scores.shape[0]), y]  # http://stackoverflow.com/a/23435843/459241\n",
    "    margins = np.maximum(0, scores - np.reshape(yi_scores, (-1, 1)) + 1)\n",
    "    margins[np.arange(num_train), y] = 0\n",
    "    loss = np.mean(np.sum(margins, axis=1))\n",
    "    loss += reg * np.sum(W * W)\n",
    "    \n",
    "    binary = margins\n",
    "    binary[margins > 0] = 1\n",
    "    row_sum = np.sum(binary, axis=1)\n",
    "    binary[np.arange(num_train), y] = -row_sum.T\n",
    "    dW = np.dot(X.T, binary)\n",
    "\n",
    "    # Average\n",
    "    dW /= num_train\n",
    "\n",
    "    # Regularize\n",
    "    dW += reg * W\n",
    "\n",
    "    return loss, dW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inViewCheck(bbox):\n",
    "    place = \"Inside\"\n",
    "    \n",
    "    if bbox[0] <    0    - 2 * bbox_l/4:\n",
    "        place = \"up-Out\"\n",
    "    if bbox[0] > frame_l - 2 * bbox_l/4:\n",
    "        place = \"down-Out\"\n",
    "    if bbox[1] <    0    - 2 * bbox_w/4:\n",
    "        place = \"left-Out\"\n",
    "    if bbox[1] > frame_w - 2 * bbox_w/4:\n",
    "        place = \"right-Out\"\n",
    "    \n",
    "    return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlineSVM(frame, bbox, W):\n",
    "    if (bbox[0] > 0 and bbox[0] < frame_l-bbox_l) and (bbox[1] > 0 and bbox[1] < frame_w-bbox_w): # This checks if child is fully inside or not\n",
    "        if direction==\"right\": \n",
    "            if bbox[1] < frame_w-2*bbox_w:\n",
    "                True_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]:bbox[1]+bbox_w]\n",
    "                Fals_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]+bbox_w:bbox[1]+2*bbox_w]\n",
    "            else:\n",
    "                True_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]:bbox[1]+bbox_w]\n",
    "                Fals_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]-bbox_w:bbox[1]]\n",
    "        elif direction==\"left\":\n",
    "            if bbox[1] > bbox_w:\n",
    "                True_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]:bbox[1]+bbox_w]\n",
    "                Fals_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]-bbox_w:bbox[1]]\n",
    "            else:\n",
    "                True_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]:bbox[1]+bbox_w]\n",
    "                Fals_patch = frame1[bbox[0]:bbox[0]+bbox_l, bbox[1]+bbox_w:bbox[1]+2*bbox_w]\n",
    "        \n",
    "        x_train = np.zeros([2, bbox_l*bbox_w*3])\n",
    "        x_train[0, :] = np.reshape(True_patch, (1, -1))\n",
    "        x_train[1, :] = np.reshape(Fals_patch, (1, -1))\n",
    "        x_train = np.hstack([x_train, np.ones((x_train.shape[0], 1))])\n",
    "        \n",
    "        data_loss, data_dW = svm_loss_vectorized(W, x_train, [1, 0], 0.000005) # 0.0005\n",
    "        W = W - 1e-7 * data_dW\n",
    "        ret = True\n",
    "    else:\n",
    "        ret = False\n",
    "    \n",
    "    return ret, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottomSearch(frame2, frame1_gray, frame2_gray, bbox):\n",
    "    correctsVal = []\n",
    "    correctsIdx = []\n",
    "    for i in range(np.int16(frame_w/(bbox_w/2)) - 2): # for i in range(9):\n",
    "        test_patch = frame2[frame_l - bbox_l:frame_l, i*np.int16(bbox_w/2):i*np.int16(bbox_w/2)+bbox_w, :]\n",
    "        test_patch_1_gray = frame1_gray[frame_l - bbox_l:frame_l, i*np.int16(bbox_w/2):i*np.int16(bbox_w/2) + bbox_w]\n",
    "        test_patch_2_gray = frame2_gray[frame_l - bbox_l:frame_l, i*np.int16(bbox_w/2):i*np.int16(bbox_w/2) + bbox_w]\n",
    "        test = np.reshape(test_patch, (1, -1))\n",
    "        test = np.hstack([test, np.ones((test.shape[0], 1))])\n",
    "        \n",
    "        subtFrames = cv.subtract(test_patch_1_gray, test_patch_2_gray)\n",
    "        ret, threshold = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        if np.count_nonzero(threshold) > 1000:\n",
    "            probability = np.max(test.dot(W))\n",
    "            predict = np.argmax(test.dot(W))\n",
    "            if predict == 1:\n",
    "                correctsVal.append(probability)\n",
    "                correctsIdx.append(i)\n",
    "    if len(correctsIdx) != 0:\n",
    "        bestCand = np.argmax(correctsVal)\n",
    "        bbox = [frame_l - np.int16(bbox_l/2), correctsIdx[bestCand]*np.int16(bbox_w/2), bbox_l, bbox_w]\n",
    "    \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftSearch(frame2, frame1_gray, frame2_gray, bbox):\n",
    "    correctsVal = []\n",
    "    correctsIdx = []\n",
    "    for i in range(np.int16(frame_l/(bbox_l/2)) - 2): # for i in range(9):\n",
    "        test_patch = frame2[i*np.int16(bbox_l/2):i*np.int16(bbox_l/2)+bbox_l, 0:bbox_w, :]\n",
    "        test_patch_1_gray = frame1_gray[i*np.int16(bbox_l/2):i*np.int16(bbox_l/2)+bbox_l, 0:bbox_w]\n",
    "        test_patch_2_gray = frame2_gray[i*np.int16(bbox_l/2):i*np.int16(bbox_l/2)+bbox_l, 0:bbox_w]\n",
    "        test = np.reshape(test_patch, (1, -1))\n",
    "        test = np.hstack([test, np.ones((test.shape[0], 1))])\n",
    "        \n",
    "        subtFrames = cv.subtract(test_patch_1_gray, test_patch_2_gray)\n",
    "        ret, threshold = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        if np.count_nonzero(threshold) > 1000:\n",
    "            probability = np.max(test.dot(W))\n",
    "            predict = np.argmax(test.dot(W))\n",
    "            if predict == 1:\n",
    "                correctsVal.append(probability)\n",
    "                correctsIdx.append(i)\n",
    "    if len(correctsIdx) != 0:\n",
    "        bestCand = np.argmax(correctsVal)\n",
    "        bbox = [0 - np.int16(bbox_w/2), correctsIdx[bestCand]*np.int16(bbox_l/2), bbox_l, bbox_w]\n",
    "    \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thewriter = csv.writer(f)\n",
    "\n",
    "# For ouput the video somewhere\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID') # Video codec parameter\n",
    "out = cv.VideoWriter('Output.avi', fourcc, 12.46, (1920, 1080))\n",
    "\n",
    "# Reading Video\n",
    "cap = cv.VideoCapture('mohamad sadra dabiri.mp4')\n",
    "\n",
    "# First frame operations\n",
    "ret, frame1= cap.read()\n",
    "\n",
    "# Define an initial bounding box\n",
    "#bbox = np.array([528, 586, 540, 320]) # amir mehdi rajabi\n",
    "#bbox = np.array([100, 100, 580, 360]) # Dorsa Ebrahimi Catted Video\n",
    "#bbox = np.array([750, 460, 640, 360]) # Ehsan Abedi\n",
    "#bbox = np.array([0, 600, 600, 340]) # Salma Javanmard Ghadiri\n",
    "#bbox = np.array([100, -100, 600, 340]) # Anita Kheiri\n",
    "#bbox = np.array([160, 1600, 560, 340]) # Aria Mansouri 01\n",
    "#bbox = np.array([80, 1450, 560, 340]) # Aria Mansouri 02\n",
    "#bbox = np.array([480, 0, 580, 380]) # Yalda Jahangiri\n",
    "#bbox = np.array([400, 1700, 800, 440]) # Yazdan Jahangiri\n",
    "#bbox = np.array([500, 1100, 700, 460]) # Yasna Mirabi\n",
    "#bbox = np.array([260, 400, 540, 400]) # Yasna Mirabi\n",
    "\n",
    "# Uncomment the line below to select a different bounding box\n",
    "bbox = cv.selectROI(frame1, False)\n",
    "bbox = np.array([bbox[1], bbox[0], bbox[3], bbox[2],])\n",
    "bbox_l, bbox_w = bbox[2], bbox[3]\n",
    "position = np.array([bbox[0] + bbox_l/2, bbox[1] + bbox_w/2])\n",
    "\n",
    "frame1_gray = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_res, prv_ori = 10, 0\n",
    "counter = 0\n",
    "direction = \"right\"\n",
    "frame_l, frame_w = np.size(frame1_gray, 0), np.size(frame1_gray, 1)\n",
    "# generate a random SVM weight matrix of small numbers\n",
    "W = np.random.randn(bbox_l*bbox_w*3 + 1, 2) * 0.0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing the video\n",
    "while(cap.isOpened()):\n",
    "#for x in range(200):\n",
    "    \n",
    "    ret, frame2 = cap.read() # Reading next frame\n",
    "    if ret == 0: # Check if next frame still exist or not (the video has been ended or not)\n",
    "        break\n",
    "    frame2_gray = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY) # Convert RGB image(frame) to grayscale\n",
    "    \n",
    "    # Check if target is going to right or left and save the state in variable named direction\n",
    "    if prv_ori > 90 and prv_ori <= 270:\n",
    "        direcion = \"left\"\n",
    "    else:\n",
    "        direcion = \"right\"\n",
    "    \n",
    "    inOrOut = inViewCheck(bbox) # This function is for checking if the child is in view or not\n",
    "    \n",
    "    if inOrOut == \"Inside\":\n",
    "        \n",
    "        ret, W = onlineSVM(frame1, bbox, W) # This function trains child patch when child is in vecinity of center of view\n",
    "        \n",
    "        u_crop, v_crop = childFlow_1(frame1_gray, frame2_gray, bbox, direction)\n",
    "        domOri, magHist = DomOriMag(u_crop, v_crop, ori_res)\n",
    "        magHist[0:np.uint8(magHist.shape[0]/10)] = 0\n",
    "        domMag = np.argmax(magHist)\n",
    "        \n",
    "        # In this part, we want to save some of our previous direction to compare with our new one and if the onlie direction\n",
    "        # completely differs from what we get in our previous loops, we will ignore that and consider our saved previous\n",
    "        # orientation except that\n",
    "        if domMag > 50: # You can remove this if you don't want to check magnitude condition if you want to consider orientation\n",
    "                        # memory for all kind of movements\n",
    "            domOri, counter = oriJumpReduct(domOri, prv_ori, counter) # To detect orientation false calculations\n",
    "        else:\n",
    "            counter = 0\n",
    "    \n",
    "        rowMove, colMove = MagOriToMove(domMag, domOri) # This function convert (Magnitude, Orintation) data to diaplacement of \n",
    "                                                        # our bounding box\n",
    "    \n",
    "        outImg = np.copy(frame1)\n",
    "        cv.rectangle(outImg, (bbox[1], bbox[0]), (bbox[1] + bbox[3], bbox[0] + bbox[2]), (255, 15, 255), 10)\n",
    "        out.write(outImg)\n",
    "        cv.namedWindow('Out', cv.WINDOW_NORMAL)\n",
    "        cv.imshow('Out', outImg)\n",
    "        \n",
    "        bbox += np.array([rowMove, colMove, 0, 0])\n",
    "    \n",
    "        ################################################\n",
    "        rowComp, colComp = MoveComp_1(frame1_gray, frame2_gray, domMag)\n",
    "        \n",
    "        bbox += np.array([rowComp, colComp, 0, 0])\n",
    "        ################################################\n",
    "        \n",
    "    elif inOrOut == \"down-Out\":\n",
    "        \n",
    "        bbox = bottomSearch(frame2, frame1_gray, frame2_gray, bbox)\n",
    "        \n",
    "        out.write(frame1)\n",
    "        cv.namedWindow('Out', cv.WINDOW_NORMAL)\n",
    "        cv.imshow('Out', frame1)\n",
    "        \n",
    "    elif inOrOut == \"left-Out\":\n",
    "        \n",
    "        bbox = bottomSearch(frame2, frame1_gray, frame2_gray, bbox)\n",
    "        \n",
    "        out.write(frame1)\n",
    "        cv.namedWindow('Out', cv.WINDOW_NORMAL)\n",
    "        cv.imshow('Out', frame1)\n",
    "    \n",
    "    frame1_gray = frame2_gray\n",
    "    frame1 = frame2\n",
    "    prv_ori = domOri\n",
    "    \n",
    "    # Exit if ESC pressed\n",
    "    k = cv.waitKey(1) & 0xff\n",
    "    if k == 27 : break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outImg = np.copy(frame1)\n",
    "#cv.rectangle(outImg, (bbox[1], bbox[0]), (bbox[1] + bbox[3], bbox[0] + bbox[2]), (255, 15, 255), 10)\n",
    "\n",
    "cv.namedWindow('Out1', cv.WINDOW_NORMAL)\n",
    "cv.imshow('Out1', np.uint8(b))\n",
    "cv.namedWindow('Out2', cv.WINDOW_NORMAL)\n",
    "cv.imshow('Out2', Fals_patch)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "p0 = cv.goodFeaturesToTrack(frame2_gray, mask = None, **feature_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 1, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u_crop, v_crop = childFlow(frame1_gray, frame2_gray, bbox, direction)\n",
    "#domOri, magHist = DomOriMag(u_crop, v_crop, ori_res)\n",
    "u_crop, v_crop = childFlow_new(frame1_gray, frame2_gray, bbox, direction)\n",
    "domOri, magHist = DomOriMag(u_crop, v_crop, ori_res)\n",
    "\n",
    "cv.namedWindow('Out1', cv.WINDOW_NORMAL)\n",
    "cv.imshow('Out1', frame1_gray)\n",
    "cv.namedWindow('Out2', cv.WINDOW_NORMAL)\n",
    "cv.imshow('Out2', frame2_gray)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106184, 2)\n",
      "(106184, 1)\n",
      "[[    0.   194.]\n",
      " [    0.   195.]\n",
      " [    0.   205.]\n",
      " ..., \n",
      " [ 1065.   923.]\n",
      " [ 1065.   925.]\n",
      " [ 1066.   927.]]\n",
      "(array([    53,     54,     55, ..., 105008, 105009, 105102], dtype=int64), array([0, 0, 0, ..., 0, 0, 0], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 4,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 3, 0.03))\n",
    "    \n",
    "bbox_new = np.copy(bbox)\n",
    "    \n",
    "# Check right side movement of bbox\n",
    "if direction == \"right\":\n",
    "    bbox_new = np.array([bbox[0], bbox[1], bbox_l, 2*bbox_w])\n",
    "    bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "elif direction == \"left\":\n",
    "    bbox_new = np.array([bbox[0], bbox[1]-bbox_w, bbox_l, 2*bbox_w])\n",
    "    bbox_new = np.clip(bbox_new, [0, 0, 0, 0], [frame_l, frame_w, frame_l, frame_w])\n",
    "        \n",
    "# Now, we will calculate optical flow and take our crop from previous step\n",
    "    \n",
    "subtFrames = cv.absdiff(frame2_gray, frame1_gray)\n",
    "ret, thresh = cv.threshold(subtFrames, 25, 255, cv.THRESH_BINARY)\n",
    "\n",
    "#thresh_crop = thresh[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "#frame1_crop = frame1_gray[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "#frame2_crop = frame2_gray[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "flow_u = np.zeros((np.size(frame1_gray, 0), np.size(frame1_gray, 1)))\n",
    "flow_v = np.zeros((np.size(frame1_gray, 0), np.size(frame1_gray, 1)))\n",
    "    \n",
    "ptsRow, ptsCol = np.nonzero(thresh)\n",
    "pts0 = np.transpose(np.array([ptsRow, ptsCol], dtype=np.float32))\n",
    "    \n",
    "pts1, st, err = cv.calcOpticalFlowPyrLK(frame1_gray, frame2_gray, pts0, None, **lk_params)\n",
    "e, f = np.nonzero(st)\n",
    "good_pts0 = pts0[e]\n",
    "good_pts1 = pts1[e]\n",
    "    \n",
    "u_v = (good_pts1 - good_pts0)\n",
    "flow_u[np.int16(good_pts0[:, 0]), np.int16(good_pts0[:, 1])] = u_v[:, 0]\n",
    "flow_v[np.int16(good_pts0[:, 0]), np.int16(good_pts0[:, 1])] = u_v[:, 1]\n",
    "    \n",
    "u_crop = flow_u[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "v_crop = flow_v[bbox_new[0]:bbox_new[0]+bbox_new[2], bbox_new[1]:bbox_new[1]+bbox_new[3]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
